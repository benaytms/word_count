{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "96848bd8-9fc9-45d9-8459-06ab72a742e5",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "<h1>\n",
    "    Word Frequency Count<br>\n",
    "</h1>\n",
    "<hr>\n",
    "<h3>\n",
    "    This was an exercise i did to practice python built-in file editing methods\n",
    "</h3>\n",
    "<h3>\n",
    "    What the word count application will do is:\n",
    "</h3>\n",
    "<h5>\n",
    "    <ul>\n",
    "        <li>Count how many unique words the text have</li>\n",
    "        <li>Tell which is the word with most frequency (it will tell all of them if multiple)</li>\n",
    "        <li>Tell which is the word with least frequency (it will tell all of them if multiple)</li>\n",
    "        <li>Creates a display file text to save the word frequency as text file</li>\n",
    "        <li>On terminal you'll have the option to search for a specific word (or a list of words separated\n",
    "        by comma) you want to know the frequency of</li>\n",
    "    </ul>\n",
    "</h5>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "83f696fb-9d81-441e-9723-c986f4d31780",
   "metadata": {},
   "outputs": [],
   "source": [
    "## module to delete the file created\n",
    "import os\n",
    "## characters to be removed from the strings\n",
    "unwanted_chars = r' ?!.(),*&%$#/\\+[]{}~\"Â´`^@:;'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "91fb6ece-ebaf-4c01-87e8-9e63c2f720a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For this you need 1) a text file to analyze and 2) a text file for the word-frequency display (can be     non-existent, empty or with already some text in it\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "File path:  /home/betomate/example.txt\n",
      "Display path:  /home/betomate/display.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The text contains 66 words (counting contractions as one)\n",
      "\n",
      "Most present word(s):  ['to', 'the', 'tales', 'of']\n",
      "Appearance count:  12\n",
      "Word count for most present:  4\n",
      "\n",
      "Least present word(s):  ['romanticize', \"we'd\", 'follow', 'path', 'hero', 'boast', 'about', 'day', 'when', 'rivers', 'overrun', 'rise', 'height', 'halo', 'as', 'rationalize', 'way', 'into', 'arms', 'savior', 'feigning', 'trials', 'tribulations', 'us', 'have', 'actually', 'been', 'there', 'not', 'like', 'ignorant', 'fibbers', 'in', 'congregation', 'gather', 'around', 'spewing', 'sympathy', 'spare', 'me', 'them', 'can', 'even', 'hold', 'a', 'candle', 'up', 'blinded', 'by', 'choice', 'these', 'hypocrites', \"won't\", 'see']\n",
      "Appearance count:  1\n",
      "Word count for least present:  54\n",
      "\n",
      "Full word-frequency: \n",
      "{'to': 12, 'the': 12, 'tales': 12, 'of': 12, 'listen': 2, 'and': 2, 'how': 2, 'we': 2, 'our': 2, 'all': 2, 'none': 2, 'you': 2, 'romanticize': 1, \"we'd\": 1, 'follow': 1, 'path': 1, 'hero': 1, 'boast': 1, 'about': 1, 'day': 1, 'when': 1, 'rivers': 1, 'overrun': 1, 'rise': 1, 'height': 1, 'halo': 1, 'as': 1, 'rationalize': 1, 'way': 1, 'into': 1, 'arms': 1, 'savior': 1, 'feigning': 1, 'trials': 1, 'tribulations': 1, 'us': 1, 'have': 1, 'actually': 1, 'been': 1, 'there': 1, 'not': 1, 'like': 1, 'ignorant': 1, 'fibbers': 1, 'in': 1, 'congregation': 1, 'gather': 1, 'around': 1, 'spewing': 1, 'sympathy': 1, 'spare': 1, 'me': 1, 'them': 1, 'can': 1, 'even': 1, 'hold': 1, 'a': 1, 'candle': 1, 'up': 1, 'blinded': 1, 'by': 1, 'choice': 1, 'these': 1, 'hypocrites': 1, \"won't\": 1, 'see': 1}\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Search for specific value? y/n:  y\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In case you want to search a list of names, the format accepted is: word1, word2, word3, ...\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Look for:  choice, around, romanticize,  none, of, listen, the\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "'choice'   Count: 1\n",
      "\n",
      "\n",
      "'around'   Count: 1\n",
      "\n",
      "\n",
      "'romanticize'   Count: 1\n",
      "\n",
      "\n",
      "'none'   Count: 2\n",
      "\n",
      "\n",
      "'of'   Count: 12\n",
      "\n",
      "\n",
      "'listen'   Count: 2\n",
      "\n",
      "\n",
      "'the'   Count: 12\n",
      "\n",
      "\n",
      "Full word-frequency in text file created\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Wish to save [1] or delete [0] file? 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File saved at /home/betomate/display.txt\n"
     ]
    }
   ],
   "source": [
    "## get-path this function is for receiving the paths for the files\n",
    "def gpath():\n",
    "    print(\"For this you need 1) a text file to analyze and 2) a text file for the word-frequency display (can be \\\n",
    "    non-existent, empty or with already some text in it\")\n",
    "    textfile = str(input(\"File path: \"))\n",
    "    displaypath = str(input(\"Display path: \"))\n",
    "    ## textfile = \"./example.txt\"\n",
    "    ## displaypath = \"./display.txt\"\n",
    "    return (textfile, displaypath)\n",
    "\n",
    "class WordCount(object):\n",
    "    def __init__(self, path, displaypath):\n",
    "        self.path = path\n",
    "        self.displaypath = displaypath\n",
    "\n",
    "    def ctwords(self):            ## creates a dictionary with the words as keys and their counting as values\n",
    "        file = self.path\n",
    "        wordsFreq = {}\n",
    "        wordsList = []\n",
    "    \n",
    "\n",
    "        ## it opens the text file to be analyzed\n",
    "        \n",
    "        with open (file, 'r') as textfile:\n",
    "            lines = textfile.readlines()   ## separates each line by break line\n",
    "            \n",
    "            for line in lines:\n",
    "                line = line.lower()        ## converts each line to lowercase\n",
    "    \n",
    "                for char in unwanted_chars:\n",
    "                    line = line.replace(char, \" \")    ## replaces the unwanted character\n",
    "                \n",
    "                words = line.split()\n",
    "                wordsList.extend(words)             ## put the words into the list\n",
    "            \n",
    "            for word in wordsList:\n",
    "                if word not in wordsFreq.keys() and word != '':     ## if the word is not on the dictionary already, add them\n",
    "                    wordsFreq[word] = wordsList.count(word)\n",
    "\n",
    "        return wordsFreq\n",
    "        \n",
    "    ## get words on extremes and sorts the frequency dictionary by descending order\n",
    "    def gwords(self):\n",
    "        wordsFreq = self.ctwords()\n",
    "        sortedFreq = dict(sorted(wordsFreq.items(), key=lambda x: x[1], reverse=True))    ## creates a new dictionary, sorted by desc order\n",
    "\n",
    "        highval = max(sortedFreq.values())     ## gets highest value\n",
    "        lowval = min(sortedFreq.values())      ## gets lowest value\n",
    "\n",
    "        highkeys = []\n",
    "        lowkeys = []\n",
    "\n",
    "\n",
    "        ## this part checks if the words appear only once\n",
    "        if highval == lowval:\n",
    "            print(\"\\nAll words appear only once. No most or least frequent word.\")\n",
    "            highkeys = list(sortedFreq.keys())\n",
    "            lowkeys = list(sortedFreq.keys())\n",
    "        else:  ## this part checks if there are more than one value that appears the most and the least\n",
    "            for k, v in sortedFreq.items():\n",
    "                if v == highval:\n",
    "                    highkeys.append(k)\n",
    "                if v == lowval:\n",
    "                    lowkeys.append(k)\n",
    "\n",
    "        return (highkeys, highval, lowkeys, lowval, sortedFreq)\n",
    "\n",
    "    ## get specified word\n",
    "    def g_word(self, target, freq):\n",
    "        self.target = target\n",
    "        word_target = self.target   ## sets the word target to the variable\n",
    "\n",
    "        ## remove the unwanted chars\n",
    "        for char in unwanted_chars:\n",
    "            word_target = word_target.replace(char, \" \")\n",
    "\n",
    "        ## words that the user wants to get\n",
    "        word_target = word_target.split()\n",
    "\n",
    "        ## sets the word frequency dictionary to a variable\n",
    "        self.freq = freq\n",
    "        word_frequency = self.freq\n",
    "\n",
    "        for word in word_target:  ## goes through each target word and if it's in the word frequency dictionary, prints out the count\n",
    "            if word in word_frequency:\n",
    "                print(f\"\\n'{word}'   Count: {word_frequency[word]}\\n\")\n",
    "            else:\n",
    "                print(f\"\\n{word} not found\\n\")\n",
    "\n",
    "    ## function to display the word-frequency onto the display text file\n",
    "    def display(self, freq):\n",
    "        displaypath = self.displaypath\n",
    "        \n",
    "        self.freq = freq\n",
    "        frequency = self.freq\n",
    "\n",
    "        ## iterates through the dictionary adding every word and its counter to a writtable format on lines\n",
    "        lines = []    \n",
    "        for k,v in frequency.items():\n",
    "            lines.append(f\"'{k}'   Count: {v}\\n\")\n",
    "        ## to make it easier to write the display file, it's all put into one string variable\n",
    "        linesFormatted = ''.join(lines)\n",
    "        \n",
    "        with open(displaypath, 'w+') as display:\n",
    "            ## goes to start, clears everything (truncate sends the pointer to end of file), and goes back to start\n",
    "            ## this step is important in case the file already has some information\n",
    "            display.seek(0)\n",
    "            display.truncate()\n",
    "            display.seek(0)\n",
    "            display.write(linesFormatted)     # writes the information into the file\n",
    "            display.flush()                   # make sure it writes without having to close the open() method\n",
    "\n",
    "            ## checks if user wants to save the file or delete it\n",
    "            try:\n",
    "                user = int(input(\"Wish to save [1] or delete [0] file?\"))\n",
    "                    \n",
    "                if user >= 1:\n",
    "                    ## because open() with the w+ mode already saves it default, we don't have to do anything\n",
    "                    print(f\"File saved at {displaypath}\")\n",
    "                    pass\n",
    "                else:\n",
    "                    ## in case the user wants to delete the file, clears the text and removes the file\n",
    "                    display.seek(0)\n",
    "                    display.truncate()\n",
    "                    os.remove(displaypath)\n",
    "                    print(\"File deleted\")\n",
    "                    \n",
    "            except Exception as e:\n",
    "                ## catches exceptions\n",
    "                print(\"Error occurred! Type: \", e)\n",
    "                os.remove(displaypath)\n",
    "                print(\"File deleted\")\n",
    "            \n",
    "\n",
    "    ## this function is to better organize everything\n",
    "    def main(self):\n",
    "        most_freq, highval, least_freq, lowval, fullFreq = count_obj.gwords()\n",
    "\n",
    "        print(f\"\\nThe text contains {len(fullFreq)} words (counting contractions as one)\")\n",
    "\n",
    "        print(\"\\nMost present word(s): \", most_freq)\n",
    "        print(\"Appearance count: \", highval)\n",
    "        print(\"Word count for most present: \", len(most_freq))\n",
    "        \n",
    "        print(\"\\nLeast present word(s): \", least_freq)\n",
    "        print(\"Appearance count: \", lowval)\n",
    "        print(\"Word count for least present: \", len(least_freq))\n",
    "\n",
    "        print(f\"\\nFull word-frequency: \\n{fullFreq}\\n\")\n",
    "        \n",
    "        user = str(input(\"Search for specific value? y/n: \"))\n",
    "        if user not in 'Nn':\n",
    "            print(\"In case you want to search a list of names, the format accepted is: word1, word2, word3, ...\")\n",
    "            target = str(input(\"Look for: \")).lower()\n",
    "            self.g_word(target, fullFreq)\n",
    "        else:\n",
    "            pass\n",
    "        \n",
    "        print(\"\\nFull word-frequency in text file created\")\n",
    "        self.display(fullFreq)\n",
    "\n",
    "\n",
    "try:\n",
    "    filepath, displaypath = gpath()\n",
    "    count_obj = WordCount(filepath, displaypath)\n",
    "    count_obj.main()\n",
    "except Exception as e:\n",
    "    print(f\"Text could not be analyzed, error: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "697c5b4e-7b5a-4b91-ac3f-a5d8d0f503b2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
